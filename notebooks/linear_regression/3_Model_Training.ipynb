{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model Training and Evaluation \n",
    "## 1. Overview\n",
    "\n",
    "In this section, we will focus on training a Linear Regression model to predict the target variable from the diabetes dataset. Linear Regression is a widely used statistical method for predicting a continuous target variable based on one or more predictor variables. \n",
    "\n",
    "We will implement two approaches to training the model:\n",
    "\n",
    "1. **Custom Implementation**: We will create our own Linear Regression class that uses the Normal Equation for fitting the model to the data. This approach will help us understand the underlying mechanics of the algorithm.\n",
    "  \n",
    "2. **Scikit-learn Implementation**: We will utilize the built-in Linear Regression model from the `sklearn.linear_model` module. This will allow us to compare the results from our custom implementation with a well-established library, ensuring that our implementation is correct.\n",
    "\n",
    "By comparing both implementations, we can validate the correctness of our custom model and gain insights into how different libraries handle model training and fitting.\n",
    "\n",
    "Refer to the file [train_linear_regression.py](../../src/train_linear_regression.py) for further details"
   ],
   "id": "fb64475217df89ed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Data Splitting\n",
    "\n",
    "We start by splitting the diabetes dataset into training and test sets using `train_test_split`. A training size of 0.8 will ensure we have enough data to fit the model.\n",
    "```python\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=49)\n",
    "```"
   ],
   "id": "9af4bec2f6bb2b1e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Model Implementation\n",
    "\n",
    "### Custom Implementation \n",
    "Next, we fit our training data using our custom Linear Regression implementation, which utilizes the Normal Equation. This approach allows us to understand the underlying mechanics of linear regression and compare it with established libraries like sklearn.\n",
    "\n",
    "```python\n",
    "# Train using custom implementation (Uses Normal Equation)\n",
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "### Scikit Learn Implementation\n",
    "After fitting our training data using the custom implementation, we will also fit the model using the Scikit-learn library’s `LinearRegression` class. This allows us to compare the coefficients obtained from both implementations and verify their consistency.\n",
    "\n",
    "```python\n",
    "# Train using scikit-learn implementation\n",
    "sk_linear_regression = SKLinearRegression()\n",
    "sk_linear_regression.fit(X_train, y_train)\n",
    "\n",
    "# Extract coefficients and intercept from the sklearn model\n",
    "sk_theta = [sk_linear_regression.intercept_] + list(sk_linear_regression.coef_)\n",
    "```\n",
    "\n",
    "### Comparing Coefficients\n",
    "\n",
    "Once we have trained both the custom implementation and the Scikit-Learn implementation, it's essential to compare the coefficients (thetas) obtained from each model. This comparison helps to validate our custom implementation against a well-established library.\n",
    "\n",
    "To facilitate this comparison, we will extract the coefficients from both models and present them side by side. This will allow us to verify that both implementations yield consistent results.\n",
    "\n",
    "```python\n",
    "theta = linear_regression.theta\n",
    "\n",
    "# Create parameters for the linear regression model\n",
    "parameters = ['theta_' + str(i) for i in range(len(theta))]\n",
    "columns = ['intercept'] + list(X.columns.values)\n",
    "parameter_df = pd.DataFrame({\n",
    "    'Parameters': parameters,\n",
    "    'Columns': columns,\n",
    "    'Theta': theta\n",
    "})\n",
    "\n",
    "# Join the sklearn parameters to the existing DataFrame\n",
    "parameter_df = parameter_df.join(pd.Series(sk_theta, name='Sklearn_theta'))\n",
    "```\n",
    "We see that the coefficients are matching and so from here onwards we'll just be using our custom implementation for further analysis."
   ],
   "id": "74dcb056337c4104"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Model Evaluation on Training Data\n",
    "\n",
    "With the coefficients validated and confirmed to be matching between our custom implementation and the Scikit-Learn implementation, we will proceed to evaluate the performance of our model on the training data. This evaluation will provide insights into how well the model has learned from the training dataset.\n",
    "\n",
    "To evaluate the model, we will calculate metrics such as Mean Squared Error (MSE) and R-squared (R²). These metrics will help us understand the accuracy of our predictions and the proportion of variance in the target variable that can be explained by our model.\n",
    "\n",
    "```python\n",
    "# Model Evaluation\n",
    "y_train_pred = linear_regression.predict(X_train)\n",
    "J_mse, r_square = linear_regression.evaluate(X_train, y_train)\n",
    "\n",
    "print('Mean Squared Error (MSE) on training data:', J_mse)\n",
    "print('R-squared (R²) on training data:', r_square)\n",
    "```\n"
   ],
   "id": "91e4966f79839219"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Visualization of Predicted vs Actual Values\n",
    "\n",
    "Next, we will visualize the relationship between the predicted values and the actual values from the training dataset. This visualization serves several important purposes:\n",
    "\n",
    "1. **Model Performance Insight**: By plotting predicted values against actual values, we can visually assess how well our model is performing. Ideally, if the model is accurate, the predicted values should closely align with the actual values.\n",
    "\n",
    "2. **Identifying Patterns and Trends**: Visualizations can help us identify any patterns, trends, or potential outliers in the data that might not be apparent through numerical metrics alone. \n",
    "\n",
    "3. **Model Improvements**: Observing the plot can highlight areas where the model may be under performing, indicating potential avenues for improvement, such as feature engineering or parameter tuning.\n",
    "\n",
    "To create this visualization, we will generate a scatter plot where the x-axis represents the actual values, and the y-axis represents the predicted values:\n",
    "\n",
    "```python\n",
    "# Visualize Predicted vs Actual Values\n",
    "visualize.plot_actual_vs_predicted(y_train, y_train_pred)\n",
    "```"
   ],
   "id": "ff802c597c9b6212"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
